#imports
import plotly.figure_factory as ff
import plotly.graph_objects as go
import plotly.express as px
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import seaborn as sns
from scipy.stats import lognorm


#Load the data and preview
df_1930 = pd.read_csv("../Data/1930_falls.csv", index_col = [0])

df_1930.head(25)





# Keep only relevant columns
df1 = df_1930.loc[:, ("name", "recclass", "mass (g)", "year", "reclat", "reclong", "country", "continent")]

#rename columns
df1.rename(columns = {'recclass': 'class', 'mass (g)': 'mass[g]', 'reclat': 'latitude', 'reclong': 'longitude'}, inplace = True)

df1.head()



print(df1['class'].unique().shape[0])

print()
df1['class'].unique()





# create a list of our conditions
conditions = [
    (df1['class'].isin(['L6', 'H6', 'LL6', 'CM2', 'OC',
               'L5', 'H4', 'H5-6', 'H3-6','CI1', 
               'CO3.2', 'CK4', 'H', 'L4', 'LL5',
              'H5', 'LL', 'R3.8-6', 'LL4'])),
    (df1['class'].isin(['Howardite', 'Aubrite', 'Eucrite-pmict', 
                 'Eucrite-mmict', 'Mesosiderite-A1',
                'Mesosiderite-A3', 'Diogenite', 'Iron, IAB-sLL',
                'Iron, IIIAB', 'Iron, IIF'])),
    (df1['class'] == 'Winonaite'),
    (df1['class'] == 'Stone-uncl'),]

# create a list of the values we want to assign for each condition
values = ['Chondrite', 'Achondrite', 'Primitive Achondrite', 'Stony-unclassified']

# create a new column and use np.select to assign values to it using our lists as arguments
df1['Type'] = np.select(conditions, values)

# display updated DataFrame
df1.head(6)


#rename the 'class' column again to match the new classification system
df1.rename(columns = {'class': 'group'}, inplace = True)

df1.head(6)


#check for missing values
df1.isnull().sum()


#display the rows with missing values
display(df1[df1.isna().any(axis=1)])


#display complete classification scheme to evaluate possible imputation strategies
grouped_by_type = df1.groupby(['Type', 'group'])['name'].count().reset_index(name = 'count')

grouped_by_type['percentage[%]'] = 100 * grouped_by_type['count']  / grouped_by_type['count'].sum()

grouped_by_type


#display the 'OC' types to see if mean or hot/cold deck imputations are reasonable
display(df1[df1['group'] == 'OC'])





#display the 'H5' types to see if mean or hot/cold deck imputations are reasonable
display(df1[df1['group'] == 'H5'])





#calculate the means of the missing types

print('\033[1m' + 'The mean mass for OC meteorites observed in the 1930s:' + '\033[0m')
print(str(round(df1[df1['group'] == 'OC']['mass[g]'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for H5 meteorites observed in the 1930s:' + '\033[0m')
print(str(round(df1[df1['group'] == 'H5']['mass[g]'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for unclassified stony meteorites observed in the 1930s:' + '\033[0m')
print(str(round(df1[df1['group'] == 'Stone-uncl']['mass[g]'].mean(), 4)))
print()


#import the data
fell_df = pd.read_csv('../Data/fell.csv', index_col = [0])

print('\033[1m' + 'The mean mass for all observed OC meteorites:' + '\033[0m')
print(str(round(fell_df[fell_df['recclass'] == 'OC']['mass (g)'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for all observed H5 meteorites:' + '\033[0m')
print(str(round(fell_df[fell_df['recclass'] == 'H5']['mass (g)'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for all observed Stone-uncl meteorites:' + '\033[0m')
print(str(round(fell_df[fell_df['recclass'] == 'Stone-uncl']['mass (g)'].mean(), 4)) + 'g')





#load the csv
met_df = pd.read_csv('../Data/Meteorite_Landings.csv')

print('\033[1m' + 'The mean mass for all observed and found OC meteorites:' + '\033[0m')
print(str(round(met_df[met_df['recclass'] == 'OC']['mass (g)'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for all observed and found H5 meteorites:' + '\033[0m')
print(str(round(met_df[met_df['recclass'] == 'H5']['mass (g)'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for all observed and found Stone-uncl meteorites:' + '\033[0m')
print(str(round(met_df[met_df['recclass'] == 'Stone-uncl']['mass (g)'].mean(), 4)) + 'g')


#imputing the mean observed OC mass for the 'Belville' meteorite
df1.loc[[92], 'mass[g]'] = 1037.8111
#imputing the mean observed(1930s) H5 mass for the 'Malotas' meteorite
df1.loc[[576], 'mass[g]'] = 4676.9167
#imputing the mean observed mass for the 'Wuzhi' meteorite
df1.loc[[1075], 'mass[g]'] = 5222.1167


#check for missing values
df1.isnull().sum()


#check the mean values again to see if any significant bias was introduced

print('\033[1m' + 'The mean mass for OC meteorites observed in the 1930s:' + '\033[0m')
print(str(round(df1[df1['group'] == 'OC']['mass[g]'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for H5 meteorites observed in the 1930s:' + '\033[0m')
print(str(round(df1[df1['group'] == 'H5']['mass[g]'].mean(), 4)) + 'g')
print()
print('\033[1m' + 'The mean mass for unclassified stony meteorites observed in the 1930s:' + '\033[0m')
print(str(round(df1[df1['group'] == 'Stone-uncl']['mass[g]'].mean(), 4)) + 'g')
print()











#verify that there are 4 categories
print('\033[1m' + 'The total number of categories' + '\033[0m')
print(df1['Type'].unique().shape[0])
print()
#check the names
print('\033[1m' + 'The new category names' + '\033[0m')
print(df1['Type'].unique())
print()
#caluculate the percentage of each category
print('\033[1m' + 'The percentage of each meteorite type' + '\033[0m')
print()
print("The percentage of Chondrites:", round(len(df1[df1['Type'] == 'Chondrite']) / len(df1.index) * 100, 4), '%')
print()
print("The percentage of Achondrites:", round(len(df1[df1['Type'] == 'Achondrite']) / len(df1.index) * 100, 4), '%')
print()
print("The percentage of Primitive Achondrites:", round(len(df1[df1['Type'] == 'Primitive Achondrite']) / len(df1.index) * 100, 4), '%')
print()
print("The percentage of unclassified meteorites:", round(len(df1[df1['Type'] == 'Stony-unclassified']) / len(df1.index) * 100, 4), '%')


#create dataframe of the main types to be displayed in a bar plot
types_dict = {'Type' : ['Chondrites', 'Achondrites', 'Primitive Achondrites', 'Stony-unclassified'],
             'Percentage' : [79.1, 18.7, 1.1, 1.1]}

types_df = pd.DataFrame(data = types_dict)

types_df


#Render the information above as a graph for presentation
fig = px.bar(types_df, x = 'Type', y = 'Percentage',
             hover_data=['Type', 'Percentage'], color='Type', hover_name = 'Type', 
             color_discrete_sequence=px.colors.qualitative.T10)

fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'}, height=600, width=700, 
                  title_text = 'The percentage of each type of meteorite')

fig.show()


#this is a repeat of the previous graph with a different orientation 
#this is just to offer alternative final report design options
fig = px.bar(types_df, x = 'Percentage', y = 'Type',
             hover_data=['Type', 'Percentage'], color='Type', hover_name = 'Type',
             orientation = 'h', color_discrete_sequence=px.colors.qualitative.T10)

fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'}, height=400, width=900, 
                  title_text = 'The percentage of each type of meteorite')

fig.update_yaxes(categoryorder = "total ascending")

fig.show()





#sort the 'grouped_by_type' frame such that the swarmplot will display the types in descending order
grouped_by_type.sort_values(by = 'percentage[%]', ascending = False, inplace = True)

grouped_by_type.head()



#use seaborn to plot the swarmplot
#uncomment next line to control the size of the figure
plt.figure(figsize=(10,5))
_ = sns.swarmplot(data=grouped_by_type, x = "Type", y = "percentage[%]", hue="Type", size = 11, palette = 'Set2')
ticks_loc = list(_.get_xticks())
_.xaxis.set_major_locator(ticker.FixedLocator(ticks_loc))
_.set_xticklabels(
    labels=["Chondrite", "Achondrite", "Primitive Achondrite", "Stony-unlassified"], rotation=30)
_.set(title = 'The percentage of each type of meteorite')
plt.show()


import plotly.express as px

fig = px.scatter(grouped_by_type, x="Type", y="percentage[%]", color="Type", size=[11]*len(grouped_by_type), 
                 color_discrete_sequence=px.colors.qualitative.Set2)
fig.update_layout(xaxis={'tickmode': 'array', 'tickvals': ticks_loc, 'ticktext': ["Chondrite", "Achondrite", 
                         "Primitive Achondrite", "Stony-unclassified"], 'tickangle': 30}, 
                  title="The percentage of each type of meteorite")
fig.show()


import plotly.express as px

fig = px.scatter(grouped_by_type, x="Type", y="percentage[%]", color="Type",
                  size="percentage[%]", size_max=30,
                  hover_data=grouped_by_type[["Type", "percentage[%]"]],
                  color_discrete_map={
                    "Chondrite": "red",
                    "Achondrite": "blue",
                    "Primitive Achondrite": "green",
                    "Stony-unlassified": "yellow",
                  })

fig.update_xaxes(
    title="Type",
    tickangle=30,
    tickvals=["Chondrite", "Achondrite", "Primitive Achondrite", "Stony-unlassified"],
)

fig.update_layout(
    title="The percentage of each type of meteorite"
)

fig.show()


#option 3 - pie chart

fig = px.pie(types_df, values = 'Percentage', names = 'Type',
             color_discrete_sequence=px.colors.qualitative.Set2)

fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'}, height=600, width=600, 
                  title_text = 'The percentage of each type of meteorite')



fig.show()


#create an exploded version of the graph above to increase legibility
import plotly.graph_objs as go


fig = go.Figure(data=[go.Pie(labels=types_df['Type'], 
                             values=types_df['Percentage'], 
                             hole=.6,
                             marker=dict(colors=['#f5cba7','#b2babb','#a9cce3','#f1948a'],
                                         line=dict(color='#000000', width=1)),
                             pull=[0, 0, 0.2, 0.2])])

fig.update_layout(title='The percentage of each type of meteorite',
                  legend_title='Type',
                  font=dict(size=16))

fig.show()


fig = go.Figure(data=[go.Pie(labels=types_df['Type'], 
                             values=types_df['Percentage'], 
                             hole=.4, 
                             marker=dict(colors=['rgb(102,194,165)', 'rgb(252,141,98)', 'rgb(141,160,203)', 'rgb(231,138,195)'], 
                                         line=dict(color='rgb(89, 89, 89)', width=1)),
                             opacity=0.9,
                             pull=[0.05, 0.05, 0.6, 0.6])])

fig.update_layout(
    title="Percentage of Meteorite Types",
    height=600,
    width=800,
    margin=dict(t=20, b=0, l=0, r=0)
    
)

fig.show()


print(px.colors.qualitative.Set2)





#Find the years with most recoveries

grouped_by_year = df1.groupby(['year'])['name'].count().sort_values(ascending = False).reset_index(name = 'count')

grouped_by_year['percentage[%]'] = 100 * grouped_by_year['count']  / grouped_by_year['count'].sum()

grouped_by_year





#Find the years with most recoveries from the entire 'fell' dataset

#Find the years with most recoveries

fell_by_year  = fell_df.groupby(['year'])['name'].count().sort_values(ascending = False).reset_index(name = 'count')

fell_by_year['percentage[%]'] = 100 * fell_by_year['count']  / fell_by_year['count'].sum()

fell_by_year.head(10)





metcat_df = pd.read_csv("../Data/metcat.csv", index_col = [0])

metcat_df.head()


metcat_df.columns


#select and rename only columns of interest from the metcat data
metcat_df = metcat_df.loc[:, ("Name", "Type", "Class", "(A)chondrite", 
                              "Group", "Petrologic type", "Recovered weight",
                              "Find or fall", "Year", "Month", "Day", "Hour", "Locality", "Country", "Decimal latitude", "Decimal longitude")].copy()

#rename columns
metcat_df.rename(columns = {'Recovered weight': 'mass', 'Find or fall': 'fall', 'Decimal latitude': 'latitude', 'Decimal longitude': 'longitude'}, inplace = True)

metcat_df.head()



#Subset only observed recoveries (falls)

metcat_falls = metcat_df[metcat_df['fall'] == 'Fall'].copy()

metcat_falls.head()


metcat_falls.shape[0]


fell_df.shape[0]


metcat_falls['Year'].describe()


#Focus on 1933
metcat_1933 = metcat_falls[metcat_falls['Year'] == '1933'].copy()

metcat_1933.head(17)


#get the month number for sorting purposes
month_dict = {'January' : 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
              'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}

# metcat_1933 = metcat_1933.copy()

metcat_1933.loc[:, 'month_no'] = metcat_1933.loc[:, ['Month']].copy()

# pd.to_datetime(metcat_1933.month_no, format='%b').dt.month
metcat_1933.month_no = metcat_1933.month_no.map(month_dict)


metcat_1933.head(1)


metcat_1933.sort_values(by = 'month_no', inplace = True)

metcat_1933


#compare the above with NASA's dataset
display(df1[df1['year'] == 1933])


grouped_by_month_1933 = metcat_1933.groupby(['Month', 'month_no'])['Name'].count().reset_index(name = 'count')

grouped_by_month_1933.sort_values(by = 'month_no', inplace = True)

grouped_by_month_1933.head(15)


#visualize the monthly count of observed falls

#create a bar plot of the monthly observations
fig = px.bar(grouped_by_month_1933, x = 'Month', y = 'count',
             hover_data=['Month', 'count'], color='count', hover_name = 'Month', 
             color_continuous_scale = 'tealgrn')

#change the background to white
#Adjust the image scale and add title
fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'}, height=600, width=900, 
                  title_text = 'Monthly observed meteorite falls in 1933')

#display the plot
fig.show()






grouped_by_month_all = metcat_falls.groupby(['Month'])['Name'].count().reset_index(name = 'count')

grouped_by_month_all


#remove inproperly named and uncertain records
grouped_by_month_all.drop(index = [0, 2, 8, 15, 16, 17, 18], inplace = True)


grouped_by_month_all


#add the month number for sorting
grouped_by_month_all.loc[:, 'month_no'] = grouped_by_month_all.loc[:, ['Month']].copy()
grouped_by_month_all.month_no = grouped_by_month_all.month_no.map(month_dict)

#sort values by month
grouped_by_month_all.sort_values(by = 'month_no', inplace = True)

grouped_by_month_all


#visualize the monthly count of observed falls for all time

#create a bar plot of the monthly observations
fig = px.bar(grouped_by_month_all, x = 'Month', y = 'count',
             hover_data=['Month', 'count'], color='count', hover_name = 'Month', 
             color_continuous_scale = 'tealgrn')

#change the background to white
#Adjust the image scale and add title
fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'}, height=600, width=900, 
                  title_text = 'Monthly observed meteorite falls for all time')

#display the plot
fig.show()



grouped_by_month_all['count'].describe()








#preview the completed dataset
df1.head()


#display the largest mass ever found from the main dataset
display(met_df[met_df['name'] == 'Hoba'])





#max mass for 1930
print()
print('\033[1m' + 'The largest mass that fell in the 1930s' + '\033[0m')
print()
display(df1[df1['mass[g]'] == df1['mass[g]'].max()])





#summary stats for the mass that fell in the 1930s
df1['mass[g]'].describe()


#Total mass that fell in the 1930s that was recovered
print()
print('\033[1m' + 'Total mass that fell in the 1930s in grams:' + '\033[0m')
print(str(df1['mass[g]'].sum()) + ' g')
print()
print('\033[1m' + 'Total mass that fell in the 1930s in kilograms:' + '\033[0m')
print(str(round(df1['mass[g]'].sum() / 1000, 2)) + ' Kg')
print()
print('\033[1m' + 'Total mass that fell in the 1930s in metric tons:' + '\033[0m')
print(str(round(df1['mass[g]'].sum() / 1000000, 2)) + ' tons')
print()



fell_df.columns



#calculate the total mass recovered each decade
fell_df['decade'] = [ int(np.floor(year/10) * 10) for year in np.array(fell_df["year"])]

#group the events by the new 'decade' column
total_mass_by_decade = fell_df.groupby(['decade'])['mass (g)'].sum().reset_index(name="total_mass")

#preview the set
total_mass_by_decade.head(10)


#restrict the data to the last two centuries as the scarcity of values prior to the 1800s will produce a hockey stick graph
#subset the data to focus on the past two centuries
total_mass_by_decade_200 = total_mass_by_decade[(total_mass_by_decade['decade'] >= 1830) & (total_mass_by_decade['decade'] < 2010)]
#The limit is set at 2010 because the data for the 2010s is not complete in this dataset and it will produce an inaccurate decade perspective 

#preview the set
print(total_mass_by_decade_200.head(20))

#set figure size
sns.set(rc={"figure.figsize":(20, 6)})

#set the grid style
sns.set(style="whitegrid")

#the evolution of meteor observations grouped by decade
_ = sns.lineplot(data=total_mass_by_decade_200, x = 'decade', y = 'total_mass')

#set the title
_.set_title('Total meteorite mass recovered each decade', fontdict={'fontsize': 16, 'fontweight': 'medium'})

#format the ticks to match each decade and rotate the labels
#_.xaxis.set_major_locator(ticker.MultipleLocator(5))
#_.xaxis.set_major_formatter(ticker.ScalarFormatter())
#_.tick_params(axis='x', rotation=90)

plt.show()





#create a bar graph of total mass per decade
fig = px.bar(total_mass_by_decade_200, x = 'decade', y = 'total_mass',
             hover_data=['decade', 'total_mass'], color='total_mass', hover_name = 'decade', 
             color_continuous_scale = 'Tealgrn')

fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'})

fig.show()





#Check for missing mass values
fell_df['mass (g)'].isnull().sum()


#display the records with missing mass values
display(fell_df[fell_df[['mass (g)']].isna().any(axis=1)])


#Check for missing mass values in the metcat library
metcat_falls['mass'].isnull().sum()





print(metcat_falls[metcat_falls['Name'] == 'Belville'])





#display the rows of the 5 known values to extract the index
display(fell_df.loc[fell_df['name'] == 'Aire-sur-la-Lys'])
display(fell_df.loc[fell_df['name'] == 'Angers'])
display(fell_df.loc[fell_df['name'] == 'Barcelona (stone)'])
display(fell_df.loc[fell_df['name'] == 'Gao-Guenie'])
display(fell_df.loc[fell_df['name'] == 'Gasseltepaoua'])


#imputing the new values 
fell_df.loc[[12], 'mass (g)'] = 6800

fell_df.loc[[37], 'mass (g)'] = 1007

fell_df.loc[[75], 'mass (g)'] = 83.5

fell_df.loc[[319], 'mass (g)'] = 3600

fell_df.loc[[323], 'mass (g)'] = 16.7


#confirm the new count of missing mass values
fell_df['mass (g)'].isnull().sum()



#confirm the new values are properly matched to the coresponding meteorites by re-checking each of the 5 names

display(fell_df.loc[fell_df['name'] == 'Aire-sur-la-Lys'])
display(fell_df.loc[fell_df['name'] == 'Angers'])
display(fell_df.loc[fell_df['name'] == 'Barcelona (stone)'])
display(fell_df.loc[fell_df['name'] == 'Gao-Guenie'])
display(fell_df.loc[fell_df['name'] == 'Gasseltepaoua'])


#remove the remaining missing mass values
fell_df_known_mass = fell_df[fell_df['mass (g)'].notna()]

display(fell_df_known_mass.head())

print(fell_df_known_mass.isnull().sum())


fell_df_known_mass['mass (g)'].describe()


fell_df[fell_df['mass (g)'] == max(fell_df['mass (g)'])]





#get the histogram for the mass
fig = px.histogram(fell_df_known_mass, x = "mass (g)", )
fig.show()





#get the histogram for the mass on a log scale
fig = px.histogram(fell_df_known_mass, x = "mass (g)", log_y = True)
fig.show()





#search for negative mass values

#neg_mass_values = fell_df_known_mass['mass (g)'][fell_df_known_mass['mass (g)'] < 0]

fell_df_known_mass['mass (g)'].min()





fell_df_known_mass['mass (g)'].dtype





#Calculate the bin width using the Freedman-Diaconis rule
q1, q3 = np.percentile(fell_df_known_mass['mass (g)'], [25, 75])
iqr = q3 - q1
bin_width = 2 * iqr / (len(fell_df_known_mass['mass (g)'])**(1/3))

#re-plot the histogram using the calculated bins
bins = np.arange(fell_df_known_mass['mass (g)'].min(), fell_df_known_mass['mass (g)'].max() + bin_width, bin_width)

fig = px.histogram(fell_df_known_mass, x = 'mass (g)', nbins = len(bins), range_x = [bins[0], bins[-1]])

fig.show()





#get the histogram for the mass
fig = px.box(fell_df_known_mass, y = "mass (g)", log_y = True)

fig.update_layout({
'plot_bgcolor': 'rgba(0, 0, 0, 0)'}, height=600, width=600, 
                  title_text = 'Distribution of recovered meteorite masses')

fig.show()


#Function to generate the sorted data for ECDF
def ecdf(data):
    """Compute ECDF for a one-dimensional array of measurements."""
    # Number of data points: n
    n = len(data)

    # x-data for the ECDF: x
    x = np.sort(data)

    # y-data for the ECDF: y
    y = np.arange(1, n+1) / n

    return x, y

#Assign the mass column to an array
mass_array = fell_df_known_mass['mass (g)']

#Compute mass ecdf
x_mass, y_mass = ecdf(mass_array)

#Specify array of percentiles
percentiles = np.array([2.5, 25, 50, 75, 97.5])

#Compute percentiles
mass_perc = np.percentile(mass_array, percentiles)

#Print the result
print(mass_perc)



#Plot the ECDF
_ = plt.plot(x_mass, y_mass, '.')
_ = plt.xlabel('mass (g)')
_ = plt.ylabel('ECDF')

#Overlay percentiles as red diamonds
_ = plt.plot(mass_perc, percentiles/100, marker = 'D', color = 'red', linestyle = 'none')

#Show the plot
plt.show()


import plotly.graph_objects as go
from plotly.subplots import make_subplots

fig = go.Figure()

fig.add_trace(go.Scatter(mode = 'markers', x = x_mass, y = y_mass, name = 'ECDF', marker = dict(color = 'royalblue', size = 4, symbol = 'circle')))

fig.add_trace(go.Scatter(mode = 'markers', x = mass_perc, y = percentiles/100, name = 'percentile', marker = dict(color = 'firebrick', size = 12, symbol = 'diamond')))

fig.update_layout(title='ECDF of Meteorite masses for observed falls',
                   xaxis_title='mass (g)',
                   yaxis_title='ECDF')

fig.show()





fell_df_known_mass['year'].max() - fell_df_known_mass['year'].min()


fell_df_known_mass[['mass (g)', 'year']][fell_df_known_mass['year'] == fell_df_known_mass['year'].min()]


fell_df_known_mass['year'][fell_df_known_mass['year'] < 1815].value_counts().sum()





fell_df_km_after_1830 = fell_df_known_mass[fell_df_known_mass['year'] >= 1830]

print(fell_df_km_after_1830.shape[0])

display(fell_df_km_after_1830.head())

fell_df_km_after_1830.to_csv('./Data/fell_df_known_mass_after_1830.csv')


# Fit a log-normal distribution to the data
shape, loc, scale = lognorm.fit(fell_df_km_after_1830['mass (g)'])

# Create a frozen distribution with the fitted parameters
dist = lognorm(shape, loc=loc, scale=scale)

# Calculate the probability of a value between x1 and x2
p = dist.cdf(681.625) - dist.cdf(0.1)

print(p)



